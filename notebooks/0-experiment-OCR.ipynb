{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwETmlgDySr-"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i3fTYLsHwGXf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "from pytesseract import Output\n",
        "import numpy as np\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import Levenshtein"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Qa2JjU0o9v"
      },
      "source": [
        "# constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iNBJFYPdx0p4"
      },
      "outputs": [],
      "source": [
        "PDF_PATH = '../data/pv.pdf'\n",
        "PDF_PATH = '../data/extrait_PV.pdf'\n",
        "PROCESSED_DATA_PATH = '../data/processed/'\n",
        "TITLE = \"OBJET\"\n",
        "#DPI, WIDTH, HEIGHT = 72, 2480, 3508\n",
        "#DPI, WIDTH, HEIGHT = 72, 1240, 1754\n",
        "DPI, WIDTH, HEIGHT = 300, 2481, 3507\n",
        "EXTRA_HEIGHT = 100\n",
        "SIMILARITY_THRESHOLD = 0.9\n",
        "LINE_JOIN_THRESHOLD = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z88brtmtIJBs"
      },
      "outputs": [],
      "source": [
        "TITLE_LIST=[\"OBJET\",\n",
        "            \"Maitre d'ouvrage\",\n",
        "            \"Date d'ouverture des plis\",\n",
        "            \"Journaux de publication de l'avis d'AO\",\n",
        "            \"publication de l'Avis d'AO\",\n",
        "            \"ELECTRONIQUE\",\n",
        "            \"LISTE DES CONCURRENTS EVINCES A TISSUE DE L'EXAMEN DES DOSSTERS ADMINISTRATIFS\",\n",
        "            \"LISTE DES CONCURRENTS ADMISSIBLES SANS RESERVE\",\n",
        "            \"LISTE DES CONCURRENTS ADMISSIBLES AVEC RESERVE\",\n",
        "            \"MONTANT DES ACTES D'ENGAGEMENTS DES CONCURRENTS RETENUS\",\n",
        "            \"CONCURRENT INVITE A DEPOSER LE COMPLEMENT DU DOSSIER ADMINISTRATIF\",\n",
        "            \"JUSTIFICATION DU CHOIX\"\n",
        "          ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SeyamA6YOOy"
      },
      "source": [
        "# identify sections by similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTgLzjJYZzf"
      },
      "source": [
        "### Src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dWTi242WYZzg"
      },
      "outputs": [],
      "source": [
        "# Function to convert PDF to images\n",
        "def pdf_to_images(pdf_path, dpi=DPI):\n",
        "    images = convert_from_path(pdf_path, dpi=dpi)\n",
        "    return images\n",
        "\n",
        "# Function to preprocess image\n",
        "def preprocess_image(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return binary\n",
        "\n",
        "# Function to calculate text similarity using TF-IDF\n",
        "def calculate_similarity(text1, text2):\n",
        "    vectorizer = TfidfVectorizer().fit_transform([text1, text2])\n",
        "    vectors = vectorizer.toarray()\n",
        "    cosine_sim = cosine_similarity(vectors)\n",
        "    return cosine_sim[0, 1]\n",
        "\n",
        "\n",
        "# Function to find the title using text similarity\n",
        "def find_title(image, title, threshold=SIMILARITY_THRESHOLD):\n",
        "    data = pytesseract.image_to_data(image, output_type=Output.DICT)\n",
        "    n_boxes = len(data['level'])\n",
        "    lines = {}\n",
        "\n",
        "    # Group words into lines\n",
        "    for i in range(n_boxes):\n",
        "        text = data['text'][i].strip()\n",
        "        if text:\n",
        "            top = data['top'][i]\n",
        "            if top in lines:\n",
        "                lines[top].append(text)\n",
        "            else:\n",
        "                lines[top] = [text]\n",
        "    print(lines)\n",
        "    title_y = None\n",
        "    max_similarity = 0\n",
        "\n",
        "    # Calculate similarity for each line\n",
        "    for top, words in lines.items():\n",
        "        text_line = ' '.join(words)\n",
        "        similarity = calculate_similarity(title.lower(), text_line.lower())\n",
        "\n",
        "        if similarity > max_similarity and similarity >= threshold:\n",
        "            max_similarity = similarity\n",
        "            title_y = top\n",
        "\n",
        "    return title_y\n",
        "\n",
        "\n",
        "# Function to crop the section containing the title\n",
        "def crop_section(image, coordinates, extra_height=EXTRA_HEIGHT):\n",
        "    x, y, w, h = coordinates\n",
        "    #cropped_image = image[y:y+h+extra_height, x:x+w]\n",
        "    cropped_image = image[y:y+h+extra_height, 0:WIDTH]\n",
        "    return cropped_image\n",
        "\n",
        "# Function to save and display cropped images\n",
        "def save_and_display_image(image, page_number, title):\n",
        "    # Convert OpenCV image to PIL format for saving\n",
        "    cropped_image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    output_path = f'cropped_page_{page_number}_title_{title}.png'\n",
        "    cropped_image_pil.save(output_path)\n",
        "    cropped_image_pil.show()\n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igUugbIX_bjt"
      },
      "source": [
        "# join lines before processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXstgrki_ikr"
      },
      "source": [
        "### Src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "image processing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uKGiTDah7VCj"
      },
      "outputs": [],
      "source": [
        "# Function to convert PDF to images\n",
        "def pdf_to_images(pdf_path, dpi):\n",
        "    images = convert_from_path(pdf_path, dpi=dpi)\n",
        "    return images\n",
        "\n",
        "# Function to preprocess image\n",
        "def preprocess_image(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return binary\n",
        "\n",
        "# Function to save and display cropped images\n",
        "def save_and_display_image(image, page_number, title):\n",
        "    # Convert OpenCV image to PIL format for saving\n",
        "    cropped_image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    output_path = f'{PROCESSED_DATA_PATH}{title}_page_{page_number}.png'\n",
        "    cropped_image_pil.save(output_path)\n",
        "    cropped_image_pil.show()\n",
        "    return output_path\n",
        "\n",
        "# Function to crop a section\n",
        "def crop_section(image, y_up,y_down, extra_height=EXTRA_HEIGHT):\n",
        "    cropped_image = image[y_up:y_down, 0:WIDTH]\n",
        "    return cropped_image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "layout zoning functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to join close lines\n",
        "def join_close_lines(lines, threshold):\n",
        "    sorted_lines = sorted(lines.items())  # Sort lines by their top coordinate\n",
        "    joined_lines = {}\n",
        "    current_top, current_words = sorted_lines[0]\n",
        "\n",
        "    for top, words in sorted_lines[1:]:\n",
        "        if top - current_top <= threshold:\n",
        "            current_words.extend(words)\n",
        "        else:\n",
        "            joined_lines[current_top] = current_words\n",
        "            current_top, current_words = top, words\n",
        "\n",
        "    joined_lines[current_top] = current_words\n",
        "    return joined_lines\n",
        "# Function to find the title using keywords\n",
        "def find_title(image, keyword):\n",
        "    data = pytesseract.image_to_data(image, output_type=Output.DICT)\n",
        "    n_boxes = len(data['level'])\n",
        "    lines = {}\n",
        "\n",
        "    # Group words into lines\n",
        "    for i in range(n_boxes):\n",
        "        text = data['text'][i].strip()\n",
        "        if text:\n",
        "            top = data['top'][i]\n",
        "            if top in lines:\n",
        "                lines[top].append(text)\n",
        "            else:\n",
        "                lines[top] = [text]\n",
        "\n",
        "    # Join close lines\n",
        "    lines = join_close_lines(lines, threshold = LINE_JOIN_THRESHOLD)\n",
        "\n",
        "    title_y = None\n",
        "    # Check each line for keyword\n",
        "    for top, words in lines.items():\n",
        "        text_line = ' '.join(words).lower()\n",
        "        #if all(keyword in text_line for keyword in keywords):\n",
        "        if keyword in text_line:\n",
        "            print(f\"found title '{keyword}' in line '{text_line}'\")\n",
        "            title_y = top\n",
        "            break\n",
        "    return title_y\n",
        "\n",
        "def shift_dict_values(y_ups,height=HEIGHT):\n",
        "    sorted_items = sorted(y_ups.items(), key=lambda item: item[1])\n",
        "    keys, values = zip(*sorted_items)\n",
        "    # Shift the values up\n",
        "    shifted_values = list(values[1:]) + [height]\n",
        "    y_downs = dict(zip(keys, shifted_values))\n",
        "    return y_downs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ocr functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to perform OCR on the cropped section (optional)\n",
        "def perform_ocr(image):\n",
        "    text = pytesseract.image_to_string(image)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1JsSJnG8dQU"
      },
      "source": [
        "### Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qND_jRjQAgDL",
        "outputId": "b6aabe99-90e7-486b-e094-b29338a98e3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "searching for keyword objet\n",
            "found title 'objet' in line 'objet: d’alimentation potable la population des douars tifrmite ait ighir ait el hakem et travaux'\n",
            "ystart for objet is 459\n",
            "searching for keyword montant\n",
            "found title 'montant' in line 'des d'engagement des montant actes concurrents:'\n",
            "ystart for montant is 1730\n",
            "searching for keyword retenu\n",
            "found title 'retenu' in line 'concurrent retenu:'\n",
            "ystart for retenu is 2444\n",
            "searching for keyword liste\n",
            "found title 'liste' in line '-portail des marches publics www.marchespublics.gov.ma du 05/05/2024liste des'\n",
            "ystart for liste is 1060\n",
            "searching for keyword date\n",
            "found title 'date' in line 'd'ouverture des plis: 05/06/2024 a 10h date :00mn.'\n",
            "ystart for date is 626\n",
            "searching for keyword lieu\n",
            "found title 'lieu' in line 'lieu d'ouverture des plis: salle des réunions de la province de tiznit..'\n",
            "ystart for lieu is 682\n",
            "searching for keyword maitre\n",
            "found title 'maitre' in line 'd'ouvrage: président du conseil communal de la idagougmar. maitre ct'\n",
            "ystart for maitre is 570\n",
            "searching for keyword journal\n",
            "found title 'journal' in line 'publié dans le journal a diffusion nationale a savoir:'\n",
            "ystart for journal is 793\n",
            "text of objet is Objet: travaux dalimentation en eau potable pour la population des douars Tifrmite ; Ait [ghir ; Ait El Hakem Et\n",
            "Tighighite de La CT Ida Gougmar\n",
            "\f\n",
            "text of montant is Montant des actes d'engagement des concurrents:\n",
            "\n",
            " \n",
            "\n",
            "Concurrents\n",
            "\n",
            "Montants des actes d’engagement\n",
            "\n",
            " \n",
            "\n",
            "-Groupement solidaire Sté VIV AQUA SARL\n",
            "et Sté BELID DE CONSTRUCTION SARL\n",
            "\n",
            "2 652 336,00\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "-STE KHALIFID SARL\n",
            "\n",
            " \n",
            "\n",
            "2 962 208,80\n",
            "\n",
            " \n",
            "\n",
            "Vérification des montants des actes d'engagement des concurrents:\n",
            "\n",
            " \n",
            "\n",
            "Concurrents\n",
            "\n",
            "Montants des actes d'engagement aprés\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "vérifications\n",
            "-Groupement solidaire Sté VIV AQUA SARL et\n",
            "Sté BELID DE CONSTRUCTION SARL 2 652 336,00\n",
            "-STE KHALIFID SARL 2 562 208,80\n",
            "\n",
            " \n",
            "\n",
            "Liste des concurrents écartés: néant\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\f\n",
            "text of retenu is Concurrent retenu:\n",
            "\n",
            " \n",
            "\n",
            "Concurrent Montant de I'acte d'engagement\n",
            "\n",
            "STE KHALIFID SARL 2 562 208,80\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Justification du choix de l'attributaire : offre la plus avantageuse.\n",
            "Date d'achévement des travaux de la commission :13/06/2024.\n",
            "\n",
            "Fait a Idagougmar le 13/06/2024\n",
            "\f\n",
            "text of liste is -Portail des marches publics www.marcnespublics.gov.ma dau 05/05/2024Liste des\n",
            "concurrents ayant déposé leurs plis:\n",
            "Groupement solidaire Sté VIV AQUA SARL et Sté BELID DE CONSTRUCTION SARL\n",
            "STE KHALIFID SARL\n",
            "\n",
            "Liste des concurrents écartés 4 l'issue de l'examen des dossiers administratifs et techniques: Néant.\n",
            "\n",
            "Liste des concurrents admis sans réserve:\n",
            "Groupement solidaire Sté VIV AQUA SARL et Sté BELID DE CONSTRUCTION SARL\n",
            "STE KHALIFID SARL\n",
            "\n",
            "Liste des concurrents admis avec réserve: Néant.\n",
            "\f\n",
            "text of date is Date d'ouverture des plis: 03/06/2024 a 10h :‘QQmn.\n",
            "\f\n",
            "text of lieu is Lieu d’ouverture des plis: Salle des reunions de la Province de Tiznit..\n",
            "\f\n",
            "text of maitre is Maitre d'ouvrage: Président du Conseil Communal de la CT Idagougmar.\n",
            "\f\n",
            "text of journal is Publie dans le journal a alifusion nationale a savortr:\n",
            "\n",
            "- 4eY! alley : en date du 10.05.2024 sous le n° : 12 735 ;\n",
            "- liberation : en date du 10.05.2024 sous le n° : 10 218 ;\n",
            "\f\n",
            "y_ups:  {'objet': 459, 'montant': 1730, 'retenu': 2444, 'liste': 1060, 'date': 626, 'lieu': 682, 'maitre': 570, 'journal': 793}\n",
            "y_downs:  {'objet': 570, 'maitre': 626, 'date': 682, 'lieu': 793, 'journal': 1060, 'liste': 1730, 'montant': 2444, 'retenu': 3507}\n"
          ]
        }
      ],
      "source": [
        "# Main function to run the process\n",
        "def main(pdf_path, keywords, dpi=DPI):\n",
        "    # Convert PDF to images\n",
        "    images = pdf_to_images(pdf_path, dpi)\n",
        "    y_ups={}\n",
        "    for keyword in keywords:\n",
        "        print(f\"searching for keyword {keyword}\")\n",
        "        # Iterate over each page\n",
        "        for page_number, image in enumerate(images, start=1):\n",
        "            # Convert PIL image to OpenCV format\n",
        "            image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "            preprocessed_image = preprocess_image(image_cv)\n",
        "            # Perform OCR and get data with bounding boxes\n",
        "            data = pytesseract.image_to_data(preprocessed_image, output_type=Output.DICT)\n",
        "            y_start = find_title(preprocessed_image, keyword=keyword)\n",
        "            print(f'ystart for {keyword} is {y_start}')\n",
        "            if y_start is not None:\n",
        "                y_ups[keyword] = y_start\n",
        "                # Crop the section containing the title\n",
        "                #cropped_image = crop_section(preprocessed_image, y_start, data)\n",
        "                #save_and_display_image(cropped_image, page_number, keywords)\n",
        "                #text = perform_ocr(cropped_image)\n",
        "            #else:\n",
        "                #print(f\"Keywords '{keywords}' not found on Page {page_number}.\")\n",
        "    y_downs = shift_dict_values(y_ups=y_ups)\n",
        "    #cropped_images={}\n",
        "    texts = {}\n",
        "    for key in y_ups.keys():\n",
        "        y_up=y_ups[key]\n",
        "        y_down=y_downs[key]\n",
        "        cropped_image = crop_section(preprocessed_image, y_up, y_down)\n",
        "        #cropped_images[key]=cropped_image\n",
        "        text = perform_ocr(cropped_image)\n",
        "        texts[key] = text\n",
        "        print(f\"text of {key} is {text}\")\n",
        "        save_and_display_image(cropped_image, page_number, key)\n",
        "    print(\"y_ups: \", y_ups)\n",
        "    print(\"y_downs: \", y_downs)\n",
        "    return texts\n",
        "\n",
        "#keywords = [[\"objet\"],[\"journal\"],[\"date\"]]#,[\"liste\", \"concurrents\"]]\n",
        "#keywords = [(\"objet\"), (\"liste\"),(\"date\"),(\"lieu\"),(\"maitre\"), (\"journal\")]\n",
        "keywords = [(\"objet\"),(\"montant\"),(\"retenu\"), (\"liste\"),(\"date\"),(\"lieu\"),(\"maitre\"), (\"journal\")]\n",
        "texts=main(PDF_PATH, keywords)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### storing in a pandas data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [objet, montant, retenu, liste, date, lieu, maitre, journal, not_found_data]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.DataFrame(columns = keywords+[\"not_found_data\"])\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.concat([df, pd.DataFrame([texts])], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>objet</th>\n",
              "      <th>montant</th>\n",
              "      <th>retenu</th>\n",
              "      <th>liste</th>\n",
              "      <th>date</th>\n",
              "      <th>lieu</th>\n",
              "      <th>maitre</th>\n",
              "      <th>journal</th>\n",
              "      <th>not_found_data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Objet: travaux dalimentation en eau potable po...</td>\n",
              "      <td>Montant des actes d'engagement des concurrents...</td>\n",
              "      <td>Concurrent retenu:\\n\\n \\n\\nConcurrent Montant ...</td>\n",
              "      <td>-Portail des marches publics www.marcnespublic...</td>\n",
              "      <td>Date d'ouverture des plis: 03/06/2024 a 10h :‘...</td>\n",
              "      <td>Lieu d’ouverture des plis: Salle des reunions ...</td>\n",
              "      <td>Maitre d'ouvrage: Président du Conseil Communa...</td>\n",
              "      <td>Publie dans le journal a alifusion nationale a...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               objet  \\\n",
              "0  Objet: travaux dalimentation en eau potable po...   \n",
              "\n",
              "                                             montant  \\\n",
              "0  Montant des actes d'engagement des concurrents...   \n",
              "\n",
              "                                              retenu  \\\n",
              "0  Concurrent retenu:\\n\\n \\n\\nConcurrent Montant ...   \n",
              "\n",
              "                                               liste  \\\n",
              "0  -Portail des marches publics www.marcnespublic...   \n",
              "\n",
              "                                                date  \\\n",
              "0  Date d'ouverture des plis: 03/06/2024 a 10h :‘...   \n",
              "\n",
              "                                                lieu  \\\n",
              "0  Lieu d’ouverture des plis: Salle des reunions ...   \n",
              "\n",
              "                                              maitre  \\\n",
              "0  Maitre d'ouvrage: Président du Conseil Communa...   \n",
              "\n",
              "                                             journal not_found_data  \n",
              "0  Publie dans le journal a alifusion nationale a...            NaN  "
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(PROCESSED_DATA_PATH+'df.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# use embedding instead"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "image processing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to convert PDF to images\n",
        "def pdf_to_images(pdf_path, dpi):\n",
        "    images = convert_from_path(pdf_path, dpi=dpi)\n",
        "    return images\n",
        "\n",
        "# Function to preprocess image\n",
        "def preprocess_image(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return binary\n",
        "\n",
        "# Function to save and display cropped images\n",
        "def save_and_display_image(image, page_number, title):\n",
        "    # Convert OpenCV image to PIL format for saving\n",
        "    cropped_image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    output_path = f'{PROCESSED_DATA_PATH}{title}_page_{page_number}.png'\n",
        "    cropped_image_pil.save(output_path)\n",
        "    cropped_image_pil.show()\n",
        "    return output_path\n",
        "\n",
        "# Function to crop a section\n",
        "def crop_section(image, y_up,y_down, extra_height=EXTRA_HEIGHT):\n",
        "    cropped_image = image[y_up:y_down, 0:WIDTH]\n",
        "    return cropped_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "layout zoning functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to join close lines\n",
        "def join_close_lines(lines, threshold):\n",
        "    sorted_lines = sorted(lines.items())  # Sort lines by their top coordinate\n",
        "    joined_lines = {}\n",
        "    current_top, current_words = sorted_lines[0]\n",
        "\n",
        "    for top, words in sorted_lines[1:]:\n",
        "        if top - current_top <= threshold:\n",
        "            current_words.extend(words)\n",
        "        else:\n",
        "            joined_lines[current_top] = current_words\n",
        "            current_top, current_words = top, words\n",
        "\n",
        "    joined_lines[current_top] = current_words\n",
        "    return joined_lines\n",
        "# Function to find the title using keywords\n",
        "def find_title(image, keyword):\n",
        "    data = pytesseract.image_to_data(image, output_type=Output.DICT)\n",
        "    n_boxes = len(data['level'])\n",
        "    lines = {}\n",
        "\n",
        "    # Group words into lines\n",
        "    for i in range(n_boxes):\n",
        "        text = data['text'][i].strip()\n",
        "        if text:\n",
        "            top = data['top'][i]\n",
        "            if top in lines:\n",
        "                lines[top].append(text)\n",
        "            else:\n",
        "                lines[top] = [text]\n",
        "\n",
        "    # Join close lines\n",
        "    lines = join_close_lines(lines, threshold = LINE_JOIN_THRESHOLD)\n",
        "\n",
        "    title_y = None\n",
        "    # Check each line for keyword\n",
        "    for top, words in lines.items():\n",
        "        text_line = ' '.join(words).lower()\n",
        "        #if all(keyword in text_line for keyword in keywords):\n",
        "        if keyword in text_line:\n",
        "            print(f\"found title '{keyword}' in line '{text_line}'\")\n",
        "            title_y = top\n",
        "            break\n",
        "    return title_y\n",
        "\n",
        "def shift_dict_values(y_ups,height=HEIGHT):\n",
        "    sorted_items = sorted(y_ups.items(), key=lambda item: item[1])\n",
        "    keys, values = zip(*sorted_items)\n",
        "    # Shift the values up\n",
        "    shifted_values = list(values[1:]) + [height]\n",
        "    y_downs = dict(zip(keys, shifted_values))\n",
        "    return y_downs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ocr functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to perform OCR on the cropped section (optional)\n",
        "def perform_ocr(image):\n",
        "    text = pytesseract.image_to_string(image)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main(pdf_path, dpi=DPI):\n",
        "    # Convert PDF to images\n",
        "    images = pdf_to_images(pdf_path, dpi)\n",
        "    # Iterate over each page\n",
        "    for page_number, image in enumerate(images, start=1):\n",
        "        # Convert PIL image to OpenCV format\n",
        "        image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "        preprocessed_image = preprocess_image(image_cv)\n",
        "        # Perform OCR and get data with bounding boxes\n",
        "        text = perform_ocr(preprocessed_image)\n",
        "    return text\n",
        "\n",
        "#keywords = [[\"objet\"],[\"journal\"],[\"date\"]]#,[\"liste\", \"concurrents\"]]\n",
        "#keywords = [(\"objet\"), (\"liste\"),(\"date\"),(\"lieu\"),(\"maitre\"), (\"journal\")]\n",
        "#keywords = [(\"objet\"),(\"montant\"),(\"retenu\"), (\"liste\"),(\"date\"),(\"lieu\"),(\"maitre\"), (\"journal\")]\n",
        "text=main(PDF_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Royaume du Maroc\n",
            "CT Idagougmar\n",
            "\n",
            "Extrait du procés-verbal de la séance de L'appel d'offres n° 03/2024\n",
            "\n",
            "Objet: travaux d’alimentation en eau potable pour la population des douars Tifrmite ; Ait Ighir ; Ait El Hakem Et\n",
            "Tighighite de La CT Ida Gougmar\n",
            "\n",
            "Maitre d'ouvrage: Président du Conseil Communal de la CT Idagougmar.\n",
            "\n",
            "Date d'ouverture des plis: 05/06/2024 a 10h :00mn.\n",
            "\n",
            "Lieu d'ouverture des plis: Salle des réunions de la Province de Tiznit..\n",
            "\n",
            "Publié dans le journal a diffusion nationale a savoir:\n",
            "\n",
            "- 4eY! alley : en date du 10.05.2024 sous le n° : 12 735 ;\n",
            "- liberation : en date du 10.05.2024 sous le n° : 10 218 ;\n",
            "\n",
            "-Portail des marches publics www.marchespublics.gov.ma du 05/05/2024Liste des\n",
            "concurrents ayant déposé leurs plis:\n",
            "\n",
            "Groupement solidaire Sté VIV AQUA SARL et Sté BELID DE CONSTRUCTION SARL\n",
            "STE KHALIFID SARL\n",
            "\n",
            "Liste des concurrents écartés 4 l'issue de l'examen des dossiers administratifs et techniques: Néant.\n",
            "Liste des concurrents admis sans réserve:\n",
            "\n",
            "Groupement solidaire Sté VIV AQUA SARL et Sté BELID DE CONSTRUCTION SARL\n",
            "\n",
            "STE KHALIFID SARL\n",
            "\n",
            "Liste des concurrents admis avec réserve: Néant.\n",
            "\n",
            "Montant des actes d'engagement des concurrents:\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Concurrents Montants des actes d’engagement\n",
            "-Groupement solidaire Sté VIV AQUA SARL\n",
            "et Sté BELID DE CONSTRUCTION SARL 2 652 336,00\n",
            "-STE KHALIFID SARL 2 562 208,80\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Vérification des montants des actes d'engagement des concurrents:\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "C Montants des actes d'engagement aprés\n",
            "oncurrents aos :\n",
            "vérifications\n",
            "-Groupement solidaire Sté VIV AQUA SARL et\n",
            "Sté BELID DE CONSTRUCTION SARL 2 652 336,00\n",
            "-STE KHALIFID SARL 2 562 208,80\n",
            "Liste des concurrents écartés: néant\n",
            "Concurrent retenu:\n",
            "Concurrent Montant de I'acte d'engagement\n",
            "STE KHALIFID SARL 2 562 208,80\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Justification du choix de l'attributaire : offre la plus avantageuse.\n",
            "Date d'achévement des travaux de la commission :13/06/2024.\n",
            "\n",
            "Fait a Idagougmar le 13/06/2024\n",
            "\f\n"
          ]
        }
      ],
      "source": [
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def normalize_whitespace(text):\n",
        "    # Replace multiple whitespace characters with a single space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Strip leading and trailing whitespace\n",
        "    text = text.strip()\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Royaume du Maroc\n",
            "CT Idagougmar\n",
            "\n",
            "Extrait du procés-verbal de la séance de L'appel d'offres n° 03/2024\n",
            "\n",
            "Objet: travaux d’alimentation en eau potable pour la population des douars Tifrmite ; Ait Ighir ; Ait El Hakem Et\n",
            "Tighighite de La CT Ida Gougmar\n",
            "\n",
            "Maitre d'ouvrage: Président du Conseil Communal de la CT Idagougmar.\n",
            "\n",
            "Date d'ouverture des plis: 05/06/2024 a 10h :00mn.\n",
            "\n",
            "Lieu d'ouverture des plis: Salle des réunions de la Province de Tiznit..\n",
            "\n",
            "Publié dans le journal a diffusion nationale a savoir:\n",
            "\n",
            "- 4eY! alley : en date du 10.05.2024 sous le n° : 12 735 ;\n",
            "- liberation : en date du 10.05.2024 sous le n° : 10 218 ;\n",
            "\n",
            "-Portail des marches publics www.marchespublics.gov.ma du 05/05/2024Liste des\n",
            "concurrents ayant déposé leurs plis:\n",
            "\n",
            "Groupement solidaire Sté VIV AQUA SARL et Sté BELID DE CONSTRUCTION SARL\n",
            "STE KHALIFID SARL\n",
            "\n",
            "Liste des concurrents écartés 4 l'issue de l'examen des dossiers administratifs et techniques: Néant.\n",
            "Liste des concurrents admis sans réserve:\n",
            "\n",
            "Groupement solidaire Sté VIV AQUA SARL et Sté BELID DE CONSTRUCTION SARL\n",
            "\n",
            "STE KHALIFID SARL\n",
            "\n",
            "Liste des concurrents admis avec réserve: Néant.\n",
            "\n",
            "Montant des actes d'engagement des concurrents:\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Concurrents Montants des actes d’engagement\n",
            "-Groupement solidaire Sté VIV AQUA SARL\n",
            "et Sté BELID DE CONSTRUCTION SARL 2 652 336,00\n",
            "-STE KHALIFID SARL 2 562 208,80\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Vérification des montants des actes d'engagement des concurrents:\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "C Montants des actes d'engagement aprés\n",
            "oncurrents aos :\n",
            "vérifications\n",
            "-Groupement solidaire Sté VIV AQUA SARL et\n",
            "Sté BELID DE CONSTRUCTION SARL 2 652 336,00\n",
            "-STE KHALIFID SARL 2 562 208,80\n",
            "Liste des concurrents écartés: néant\n",
            "Concurrent retenu:\n",
            "Concurrent Montant de I'acte d'engagement\n",
            "STE KHALIFID SARL 2 562 208,80\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Justification du choix de l'attributaire : offre la plus avantageuse.\n",
            "Date d'achévement des travaux de la commission :13/06/2024.\n",
            "\n",
            "Fait a Idagougmar le 13/06/2024\n",
            "\f\n"
          ]
        }
      ],
      "source": [
        "text_processed = normalize_whitespace(text)\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cuphead/Projects/OCR marche publiques/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'CamembertTokenizerFast'. \n",
            "The class this function is called from is 'BertTokenizer'.\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "stat: path should be string, bytes, os.PathLike or integer, not NoneType",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#import torch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load pre-trained BERT model and tokenizer for French\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamembert-base\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mBertTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m BertModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embeddings\u001b[39m(text):\n",
            "File \u001b[0;32m~/Projects/OCR marche publiques/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2163\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2161\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2166\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2167\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Projects/OCR marche publiques/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2397\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2395\u001b[0m \u001b[38;5;66;03m# Instantiate the tokenizer.\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2397\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2398\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   2399\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m   2400\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load vocabulary from file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2401\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check that the provided vocabulary is accessible and not corrupted.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2402\u001b[0m     )\n",
            "File \u001b[0;32m~/Projects/OCR marche publiques/venv/lib/python3.10/site-packages/transformers/models/bert/tokenization_bert.py:110\u001b[0m, in \u001b[0;36mBertTokenizer.__init__\u001b[0;34m(self, vocab_file, do_lower_case, do_basic_tokenize, never_split, unk_token, sep_token, pad_token, cls_token, mask_token, tokenize_chinese_chars, strip_accents, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     97\u001b[0m     vocab_file,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    109\u001b[0m ):\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    112\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a vocabulary file at path \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvocab_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. To load the vocabulary from a Google pretrained\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m         )\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab \u001b[38;5;241m=\u001b[39m load_vocab(vocab_file)\n",
            "File \u001b[0;32m/usr/lib/python3.10/genericpath.py:30\u001b[0m, in \u001b[0;36misfile\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path is a regular file\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     st \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[0;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not NoneType"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "#import torch\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer for French\n",
        "model_name = \"camembert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)\n",
        "\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "    outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "# Example to get embeddings for a section\n",
        "section_text = \"some section text\"\n",
        "embeddings = get_embeddings(section_text)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "G4Qa2JjU0o9v",
        "OeU8NJCZ0tFW",
        "DdACh-npIRp0",
        "4AhNUEzrBVOo",
        "3Mucow-qBbSm",
        "7QTFYk4DBdE-",
        "5SeyamA6YOOy",
        "o0bXHozWs57W",
        "osoQySeds57a",
        "eVH0zi4T0eZ-",
        "WWdy31Hcs57f"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
