{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwETmlgDySr-"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i3fTYLsHwGXf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "from pytesseract import Output\n",
        "import numpy as np\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import Levenshtein"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Qa2JjU0o9v"
      },
      "source": [
        "# constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iNBJFYPdx0p4"
      },
      "outputs": [],
      "source": [
        "PDF_PATH = '../data/extrait_PV.pdf'\n",
        "PROCESSED_DATA_PATH = '../data/processed/'\n",
        "TITLE = \"OBJET\"\n",
        "#DPI, WIDTH, HEIGHT = 72, 2480, 3508\n",
        "#DPI, WIDTH, HEIGHT = 72, 1240, 1754\n",
        "DPI, WIDTH, HEIGHT = 300, 2481, 3507\n",
        "EXTRA_HEIGHT = 100\n",
        "SIMILARITY_THRESHOLD = 0.9\n",
        "LINE_JOIN_THRESHOLD = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z88brtmtIJBs"
      },
      "outputs": [],
      "source": [
        "TITLE_LIST=[\"OBJET\",\n",
        "            \"Maitre d'ouvrage\",\n",
        "            \"Date d'ouverture des plis\",\n",
        "            \"Journaux de publication de l'avis d'AO\",\n",
        "            \"publication de l'Avis d'AO\",\n",
        "            \"ELECTRONIQUE\",\n",
        "            \"LISTE DES CONCURRENTS EVINCES A TISSUE DE L'EXAMEN DES DOSSTERS ADMINISTRATIFS\",\n",
        "            \"LISTE DES CONCURRENTS ADMISSIBLES SANS RESERVE\",\n",
        "            \"LISTE DES CONCURRENTS ADMISSIBLES AVEC RESERVE\",\n",
        "            \"MONTANT DES ACTES D'ENGAGEMENTS DES CONCURRENTS RETENUS\",\n",
        "            \"CONCURRENT INVITE A DEPOSER LE COMPLEMENT DU DOSSIER ADMINISTRATIF\",\n",
        "            \"JUSTIFICATION DU CHOIX\"\n",
        "          ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SeyamA6YOOy"
      },
      "source": [
        "# identify sections by similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTgLzjJYZzf"
      },
      "source": [
        "### Src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dWTi242WYZzg"
      },
      "outputs": [],
      "source": [
        "# Function to convert PDF to images\n",
        "def pdf_to_images(pdf_path, dpi=DPI):\n",
        "    images = convert_from_path(pdf_path, dpi=dpi)\n",
        "    return images\n",
        "\n",
        "# Function to preprocess image\n",
        "def preprocess_image(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return binary\n",
        "\n",
        "# Function to calculate text similarity using TF-IDF\n",
        "def calculate_similarity(text1, text2):\n",
        "    vectorizer = TfidfVectorizer().fit_transform([text1, text2])\n",
        "    vectors = vectorizer.toarray()\n",
        "    cosine_sim = cosine_similarity(vectors)\n",
        "    return cosine_sim[0, 1]\n",
        "\n",
        "\n",
        "# Function to find the title using text similarity\n",
        "def find_title(image, title, threshold=SIMILARITY_THRESHOLD):\n",
        "    data = pytesseract.image_to_data(image, output_type=Output.DICT)\n",
        "    n_boxes = len(data['level'])\n",
        "    lines = {}\n",
        "\n",
        "    # Group words into lines\n",
        "    for i in range(n_boxes):\n",
        "        text = data['text'][i].strip()\n",
        "        if text:\n",
        "            top = data['top'][i]\n",
        "            if top in lines:\n",
        "                lines[top].append(text)\n",
        "            else:\n",
        "                lines[top] = [text]\n",
        "    print(lines)\n",
        "    title_y = None\n",
        "    max_similarity = 0\n",
        "\n",
        "    # Calculate similarity for each line\n",
        "    for top, words in lines.items():\n",
        "        text_line = ' '.join(words)\n",
        "        similarity = calculate_similarity(title.lower(), text_line.lower())\n",
        "\n",
        "        if similarity > max_similarity and similarity >= threshold:\n",
        "            max_similarity = similarity\n",
        "            title_y = top\n",
        "\n",
        "    return title_y\n",
        "\n",
        "\n",
        "# Function to crop the section containing the title\n",
        "def crop_section(image, coordinates, extra_height=EXTRA_HEIGHT):\n",
        "    x, y, w, h = coordinates\n",
        "    #cropped_image = image[y:y+h+extra_height, x:x+w]\n",
        "    cropped_image = image[y:y+h+extra_height, 0:WIDTH]\n",
        "    return cropped_image\n",
        "\n",
        "# Function to save and display cropped images\n",
        "def save_and_display_image(image, page_number, title):\n",
        "    # Convert OpenCV image to PIL format for saving\n",
        "    cropped_image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    output_path = f'cropped_page_{page_number}_title_{title}.png'\n",
        "    cropped_image_pil.save(output_path)\n",
        "    cropped_image_pil.show()\n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrnMavASYZzi"
      },
      "source": [
        "### Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igUugbIX_bjt"
      },
      "source": [
        "# join lines before processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXstgrki_ikr"
      },
      "source": [
        "### Src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "image processing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uKGiTDah7VCj"
      },
      "outputs": [],
      "source": [
        "# Function to convert PDF to images\n",
        "def pdf_to_images(pdf_path, dpi):\n",
        "    images = convert_from_path(pdf_path, dpi=dpi)\n",
        "    return images\n",
        "\n",
        "# Function to preprocess image\n",
        "def preprocess_image(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return binary\n",
        "\n",
        "# Function to save and display cropped images\n",
        "def save_and_display_image(image, page_number, title):\n",
        "    # Convert OpenCV image to PIL format for saving\n",
        "    cropped_image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    output_path = f'{PROCESSED_DATA_PATH}{title}_page_{page_number}.png'\n",
        "    cropped_image_pil.save(output_path)\n",
        "    cropped_image_pil.show()\n",
        "    return output_path\n",
        "\n",
        "# Function to crop a section\n",
        "def crop_section(image, y_up,y_down, extra_height=EXTRA_HEIGHT):\n",
        "    cropped_image = image[y_up:y_down, 0:WIDTH]\n",
        "    return cropped_image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "layout zoning functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to join close lines\n",
        "def join_close_lines(lines, threshold):\n",
        "    sorted_lines = sorted(lines.items())  # Sort lines by their top coordinate\n",
        "    joined_lines = {}\n",
        "    current_top, current_words = sorted_lines[0]\n",
        "\n",
        "    for top, words in sorted_lines[1:]:\n",
        "        if top - current_top <= threshold:\n",
        "            current_words.extend(words)\n",
        "        else:\n",
        "            joined_lines[current_top] = current_words\n",
        "            current_top, current_words = top, words\n",
        "\n",
        "    joined_lines[current_top] = current_words\n",
        "    return joined_lines\n",
        "# Function to find the title using keywords\n",
        "def find_title(image, keyword):\n",
        "    data = pytesseract.image_to_data(image, output_type=Output.DICT)\n",
        "    n_boxes = len(data['level'])\n",
        "    lines = {}\n",
        "\n",
        "    # Group words into lines\n",
        "    for i in range(n_boxes):\n",
        "        text = data['text'][i].strip()\n",
        "        if text:\n",
        "            top = data['top'][i]\n",
        "            if top in lines:\n",
        "                lines[top].append(text)\n",
        "            else:\n",
        "                lines[top] = [text]\n",
        "\n",
        "    # Join close lines\n",
        "    lines = join_close_lines(lines, threshold = LINE_JOIN_THRESHOLD)\n",
        "\n",
        "    title_y = None\n",
        "    # Check each line for keyword\n",
        "    for top, words in lines.items():\n",
        "        text_line = ' '.join(words).lower()\n",
        "        #if all(keyword in text_line for keyword in keywords):\n",
        "        if keyword in text_line:\n",
        "            print(f\"found title '{keyword}' in line '{text_line}'\")\n",
        "            title_y = top\n",
        "            break\n",
        "    return title_y\n",
        "\n",
        "def shift_dict_values(y_ups,height=HEIGHT):\n",
        "    sorted_items = sorted(y_ups.items(), key=lambda item: item[1])\n",
        "    keys, values = zip(*sorted_items)\n",
        "    # Shift the values up\n",
        "    shifted_values = list(values[1:]) + [height]\n",
        "    y_downs = dict(zip(keys, shifted_values))\n",
        "    return y_downs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ocr functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to perform OCR on the cropped section (optional)\n",
        "def perform_ocr(image):\n",
        "    text = pytesseract.image_to_string(image,lang=\"fra\")\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1JsSJnG8dQU"
      },
      "source": [
        "### Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qND_jRjQAgDL",
        "outputId": "b6aabe99-90e7-486b-e094-b29338a98e3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "searching for keyword objet\n",
            "found title 'objet' in line 'objet: d’alimentation potable la population des douars tifrmite ait ighir ait el hakem et travaux'\n",
            "ystart for objet is 459\n",
            "searching for keyword liste\n",
            "found title 'liste' in line '-portail des marches publics www.marchespublics.gov.ma du 05/05/2024liste des'\n",
            "ystart for liste is 1060\n",
            "searching for keyword date\n",
            "found title 'date' in line 'd'ouverture des plis: 05/06/2024 a 10h date :00mn.'\n",
            "ystart for date is 626\n",
            "searching for keyword lieu\n",
            "found title 'lieu' in line 'lieu d'ouverture des plis: salle des réunions de la province de tiznit..'\n",
            "ystart for lieu is 682\n",
            "searching for keyword maitre\n",
            "found title 'maitre' in line 'd'ouvrage: président du conseil communal de la idagougmar. maitre ct'\n",
            "ystart for maitre is 570\n",
            "searching for keyword journal\n",
            "found title 'journal' in line 'publié dans le journal a diffusion nationale a savoir:'\n",
            "ystart for journal is 793\n",
            "y_ups:  {'objet': 459, 'liste': 1060, 'date': 626, 'lieu': 682, 'maitre': 570, 'journal': 793}\n",
            "y_downs:  {'objet': 570, 'maitre': 626, 'date': 682, 'lieu': 793, 'journal': 1060, 'liste': 3507}\n"
          ]
        }
      ],
      "source": [
        "# Main function to run the process\n",
        "def main(pdf_path, keywords, dpi=DPI):\n",
        "    # Convert PDF to images\n",
        "    images = pdf_to_images(pdf_path, dpi)\n",
        "    y_ups={}\n",
        "    for keyword in keywords:\n",
        "        print(f\"searching for keyword {keyword}\")\n",
        "        # Iterate over each page\n",
        "        for page_number, image in enumerate(images, start=1):\n",
        "            # Convert PIL image to OpenCV format\n",
        "            image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "            preprocessed_image = preprocess_image(image_cv)\n",
        "            # Perform OCR and get data with bounding boxes\n",
        "            data = pytesseract.image_to_data(preprocessed_image, output_type=Output.DICT)\n",
        "            y_start = find_title(preprocessed_image, keyword=keyword)\n",
        "            print(f'ystart for {keyword} is {y_start}')\n",
        "            if y_start is not None:\n",
        "                y_ups[keyword] = y_start\n",
        "                # Crop the section containing the title\n",
        "                #cropped_image = crop_section(preprocessed_image, y_start, data)\n",
        "                #save_and_display_image(cropped_image, page_number, keywords)\n",
        "                #text = perform_ocr(cropped_image)\n",
        "            #else:\n",
        "                #print(f\"Keywords '{keywords}' not found on Page {page_number}.\")\n",
        "    y_downs = shift_dict_values(y_ups=y_ups)\n",
        "    cropped_images={}\n",
        "    for key in y_ups.keys():\n",
        "        y_up=y_ups[key]\n",
        "        y_down=y_downs[key]\n",
        "        cropped_image = crop_section(preprocessed_image, y_up, y_down)\n",
        "        cropped_images[key]=cropped_image\n",
        "        save_and_display_image(cropped_image, page_number, key)\n",
        "    print(\"y_ups: \", y_ups)\n",
        "    print(\"y_downs: \", y_downs)\n",
        "\n",
        "#keywords = [[\"objet\"],[\"journal\"],[\"date\"]]#,[\"liste\", \"concurrents\"]]\n",
        "keywords = [(\"objet\"), (\"liste\"),(\"date\"),(\"lieu\"),(\"maitre\"), (\"journal\")]\n",
        "main(PDF_PATH, keywords)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "G4Qa2JjU0o9v",
        "OeU8NJCZ0tFW",
        "DdACh-npIRp0",
        "4AhNUEzrBVOo",
        "3Mucow-qBbSm",
        "7QTFYk4DBdE-",
        "5SeyamA6YOOy",
        "o0bXHozWs57W",
        "osoQySeds57a",
        "eVH0zi4T0eZ-",
        "WWdy31Hcs57f"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
